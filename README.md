# S3-Lite: S3 유사 객체 저장소 구현 정리 (2025-07-23)

## 1\. 개요

- Amazon S3는 사실상 업계 표준 객체 저장소임.
- 확장성, 내구성, 가용성, 성능 모두 뛰어나서 안 쓰는 곳을 찾기 힘듦.
- 이 문서는 '가상 면접 사례로 배우는 대규모 시스템 설계 기초 2' 책을 보고 S3 비스무리한 걸 직접 만들어보려는 개발자를 위한 가이드임.
- 핵심 기능 위주로 각 컴포넌트 역할과 구현 방향을 정리했음.

-----

## 2\. 시스템 아키텍처

- 대규모 객체 저장소는 여러 컴포넌트가 맞물려 돌아가는 분산 시스템임.
- 핵심 컴포넌트는 아래와 같음.

| 컴포넌트 | 주요 역할 | 설명 |
|---|---|---|
| **API 게이트웨이** | 클라이언트 요청 처리 | S3 호환 REST API를 외부에 열어주고, 인증/인가, 요청 라우팅을 담당함. |
| **메타데이터 서비스** | 객체 정보 관리 | 객체와 버킷의 메타데이터(이름, 크기, 위치 등)를 DB에 저장하고 관리함. |
| **데이터 서비스** | 실제 데이터 저장 | 객체의 실제 데이터를 여러 스토리지 노드에 쪼개서 저장. 데이터 안 날아가게 책임짐. |
| **스토리지 노드** | 데이터 저장소 | 데이터를 물리적으로 들고 있는 서버. 그냥 디스크 달린 서버라고 보면 됨. |

**[전체 시스템 흐름]**

1.  클라이언트가 S3 API로 API 게이트웨이에 파일 올려달라고 요청함.
2.  API 게이트웨이는 이 요청을 받아 인증/인가를 처리함. 권한 없으면 여기서 컷.
3.  권한 있으면, API 게이트웨이가 메타데이터 서비스에 "이런 객체 들어올 거니 메타데이터 만들어 둬"라고 알림.
4.  메타데이터 서비스는 객체 ID를 따고, 실제 데이터가 어디 저장될지 데이터 서비스한테 물어본 뒤, 이 정보를 DB에 기록함.
5.  API 게이트웨이는 클라이언트에게 받은 파일 데이터를 데이터 서비스로 넘김.
6.  데이터 서비스는 받은 데이터를 여러 스토리지 노드에 복제(Replication) 또는 이레이저 코딩(Erasure Coding)으로 나눠서 저장함. (노드 하나 죽어도 괜찮도록)
7.  저장 끝나면 데이터 서비스가 API 게이트웨이에 "완료" 신호를 주고, 게이트웨이는 최종적으로 클라이언트에게 "성공" 응답을 보냄.

-----

## 3\. 핵심 컴포넌트 설계

### 3.1. API 게이트웨이 (API Gateway)

- 시스템의 얼굴마담. S3랑 똑같은 척하려면 RESTful API 엔드포인트를 잘 만들어야 함.

#### **필수 구현 API 목록:**

- 이거 없으면 객체 저장소라 할 수 없음.


- **Bucket Operations:**
    - `PUT /<bucket-name>`: 버킷 생성
    - `GET /`: 버킷 목록 조회
    - `DELETE /<bucket-name>`: 버킷 삭제


- **Object Operations:**
    - `PUT /<bucket-name>/<object-key>`: 객체 업로드 (핵심)
    - `GET /<bucket-name>/<object-key>`: 객체 다운로드 (핵심)
    - `DELETE /<bucket-name>/<object-key>`: 객체 삭제
    - `GET /<bucket-name>?prefix=<prefix>`: 특정 이름으로 시작하는 객체들 목록 보기

#### **인증 (Authentication):**

- S3는 모든 요청에 서명을 요구함. **AWS Signature Version 4** 방식을 똑같이 구현해서 아무나 못 쓰게 막아야 함.
  <br> 이건 일단 후순위 기능구현 먼저 ㄱㄱ
#### **대용량 객체 처리 (Multipart Upload):**

- GB 단위 큰 파일은 한 번에 올리면 불안정함. 잘라서 병렬로 올려야 빠르고 안정적임.
- **플로우:**
    1.  **업로드 시작**: `uploadId`를 먼저 발급받음. (`POST /.../?uploads`)
    2.  **조각 업로드**: 파일을 조각내서 각 조각을 병렬로 업로드함. (`PUT /.../?partNumber=N&uploadId=...`)
    3.  **업로드 완료**: 모든 조각이 올라갔다고 알리면, 서버가 조각들을 합쳐서 하나의 완전한 파일로 만듦. (`POST /.../?uploadId=...`)
    4.  **업로드 중단**: 문제 생기면 업로드 중단하고, 올라갔던 조각 파일들 다 지워야 함. (`DELETE /.../?uploadId=...`)

-----

### 3.2. 메타데이터 서비스 (Metadata Service)

- 객체의 일련번호를 관리하는 곳. 빠르고 안정적인 DB 선택이 관건.
- 보통 NoSQL(Mongo 등)을 쓰거나, RDBMS(Postgre)를 샤딩해서 씀.

#### **DB 스키마 예시:**

**Buckets 테이블:**

| 컬럼명 | 데이터 타입 | 설명 |
|---|---|---|
| `bucket_id` | VARCHAR | 버킷 고유 ID (PK) |
| `name` | VARCHAR | 버킷 이름 (Unique) |
| `owner_id` | VARCHAR | 소유자 ID |
| `created_at` | TIMESTAMP | 생성 시간 |

**Objects 테이블:**

| 컬럼명 | 데이터 타입 | 설명 |
|---|---|---|
| `object_id` | VARCHAR | 객체 고유 ID (PK) |
| `bucket_id` | VARCHAR | 소속 버킷 ID (FK) |
| `key` | VARCHAR | 객체 키 (파일 경로 같은 이름) |
| `size_bytes` | BIGINT | 파일 크기 |
| `etag` | VARCHAR | 파일 내용 해시값 (MD5) |
| `storage_info` | JSON | 실제 데이터가 어느 노드에 있는지 위치 정보 |
| `created_at` | TIMESTAMP | 생성 시간 |

> **💡 TMI: `prefix` 검색 성능 올리기**
> 객체 `key`를 B-Tree 인덱스로 만들어두면 `LIKE 'prefix%'` 같은 쿼리 날릴 때 빨라짐.

-----

### 3.3. 데이터 서비스 (Data Service)

- 실제 데이터를 저장하고 데이터의 생존을 책임지는 컴포넌트임.

#### **데이터 내구성 확보 전략 (택 1 또는 혼용):**

- **복제 (Replication):**

    - 똑같은 데이터를 통째로 여러 노드에 복사하는 단순한 방식.
    - **장점:** 구현 쉽고, 읽기 빠름.
    - **단점:** 공간 효율 꽝. (3번 복사하면 용량 3배 씀)

- **이레이저 코딩 (Erasure Coding):**

    - 데이터를 여러 조각으로 나누고, 몇 개가 사라져도 복구할 수 있는 '복구용 조각'을 추가로 만들어 저장하는 방식. (RAID-5/6와 비슷)
    - **장점:** 저장 공간을 훨씬 아낄 수 있음. (10개 원본 + 4개 복구용 = 1.4배 용량)
    - **단점:** 데이터를 읽고 쓸 때 인코딩/디코딩 계산이 들어가서 CPU를 더 씀.

#### **데이터 배치 및 추적:**

- 데이터 서비스는 항상 어떤 스토리지 노드가 살아있는지, 용량은 얼마나 남았는지 알아야 함.
- 이 정보를 바탕으로 새로 들어온 데이터를 어디에 저장할지 결정함.
- 노드 하나가 죽으면, 다른 노드의 복제본이나 복구용 조각을 이용해 데이터를 자동으로 복구해야 함.

-----

## 4\. 로드 밸런싱 및 확장성

- 사용자 늘어나면 서버도 늘려야 함. 이때 부하를 골고루 나눠주는 게 중요.
- **API 게이트웨이 앞단:** L4/L7 로드 밸런서를 둬서 들어오는 요청을 여러 게이트웨이 서버로 분산시킴.
- **데이터 트래픽 분산:** Consistent Hashing 같은 알고리즘을 사용해서 객체를 여러 스토리지 노드에 최대한 균등하게 뿌려줌. 이렇게 해야 특정 노드만 힘들어지는 '핫스팟' 현상을 막고, 나중에 노드 추가/삭제할 때 데이터 이동을 최소화할 수 있음.

-----

## 5\. 결론

- S3 따라 만들기는 대규모 분산 시스템 설계의 정수를 배울 수 있는 좋은 토이 프로젝트임.
- 이 문서는 기본 뼈대만 다뤘음. 실 서비스로 만들려면 **보안(암호화, ACL), 데이터 수명 주기 관리, 모니터링, 로깅** 등등 할 게 산더미임.
- 일단 여기서 제시한 가이드 보고 하나씩 만들어보면서 직접 고통받고 경험치를 쌓자 끝.